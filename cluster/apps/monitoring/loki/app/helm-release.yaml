---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: loki
  namespace: monitoring
spec:
  interval: 60m
  timeout: 15m
  chart:
    spec:
      # renovate: registryUrl=https://grafana.github.io/helm-charts
      chart: loki
      version: 6.6.3
      sourceRef:
        kind: HelmRepository
        name: grafana-charts
        namespace: flux-system

  maxHistory: 5
  install:
    remediation:
      retries: 4
  upgrade:
    # disableWait: true # intended to be temporary
    timeout: 15m
    remediation:
      remediateLastFailure: true
  uninstall:
    keepHistory: false
  valuesFrom:
    # Provided by rook-ceph-operator. See https://rook.io/docs/rook/v1.9/Storage-Configuration/Object-Storage-RGW/ceph-object-bucket-claim/
    - targetPath: loki.storage.bucketNames.chunks
      kind: ConfigMap
      name: &cephBucket loki-bucket-v1
      valuesKey: BUCKET_NAME
    - targetPath: loki.storage.bucketNames.ruler
      kind: ConfigMap
      name: *cephBucket
      valuesKey: BUCKET_NAME
    - targetPath: loki.storage.bucketNames.admin
      kind: ConfigMap
      name: *cephBucket
      valuesKey: BUCKET_NAME
    # This one is needed to avoid the loki helm chart magically prepending the bucket name to the endpoint
    - targetPath: loki.structuredConfig.common.storage.s3.endpoint
      kind: ConfigMap
      name: *cephBucket
      valuesKey: BUCKET_HOST
    - targetPath: loki.storage.s3.endpoint
      kind: ConfigMap
      name: *cephBucket
      valuesKey: BUCKET_HOST
    - targetPath: loki.storage.s3.region
      kind: ConfigMap
      name: *cephBucket
      valuesKey: BUCKET_REGION
    - targetPath: loki.storage.s3.accessKeyId
      kind: Secret
      name: *cephBucket
      valuesKey: AWS_ACCESS_KEY_ID
    - targetPath: loki.storage.s3.secretAccessKey
      kind: Secret
      name: *cephBucket
      valuesKey: AWS_SECRET_ACCESS_KEY
  values:
    deploymentMode: SimpleScalable

    lokiCanary:
      enabled: false

    backend:
      replicas: 2
      persistence:
        storageClass: ceph-block
      extraVolumeMounts:
        - name: rules
          mountPath: /rules/fake
        - name: scratch
          mountPath: /tmp/scratch
      extraVolumes:
        - name: rules
          configMap:
            name: loki-alerting-rules
        - name: scratch
          emptyDir: {}

    write:
      replicas: 2
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/component: write
                topologyKey: kubernetes.io/hostname
      persistence:
        size: 5Gi
        storageClass: ceph-block

    read:
      replicas: 2
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/component: read
                topologyKey: kubernetes.io/hostname
      extraVolumeMounts:
        - name: loki-rules
          mountPath: /rules
        - name: loki-rules-tmp
          mountPath: /tmp/scratch
        - name: loki-tmp
          mountPath: /tmp/loki-tmp
      extraVolumes:
        - name: loki-rules
          emptyDir: {}
          readonly: false
        - name: loki-rules-tmp
          emptyDir: {}
          readonly: false
        - name: loki-tmp
          emptyDir: {}
          readonly: false
      persistence:
        size: 5Gi
        storageClass: ceph-block

    gateway:
      enabled: true
      replicas: 2
      topologySpreadConstraints:
        - maxSkew: 2
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: loki
              app.kubernetes.io/component: gateway
      ingress:
        enabled: true
        ingressClassName: "traefik"
        annotations:
          cert-manager.io/cluster-issuer: "letsencrypt-production"
          hajimari.io/instance: "bloop-quarky"
          hajimari.io/enable: "true"
          hajimari.io/appName: "Loki"
          traefik.ingress.kubernetes.io/router.entrypoints: "websecure"
          traefik.ingress.kubernetes.io/router.middlewares: "networking-rfc1918@kubernetescrd"
        hosts:
          - host: &host "loki.${XYZ_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
        tls:
          - secretName: tls.loki
            hosts:
              - *host

    tolerations:
      - key: "arm"
        operator: "Exists"
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: app
                  operator: In
                  values:
                    - loki
            topologyKey: "kubernetes.io/hostname"

    loki:
      podAnnotations:
        configmap.reloader.stakater.com/reload: *cephBucket
        secret.reloader.stakater.com/reload: *cephBucket
      analytics:
        reporting_enabled: false
      auth_enabled: false

      schemaConfig:
        configs:
          - from: "2024-05-30"
            store: tsdb
            object_store: s3
            schema: v13
            index:
              prefix: loki_index_
              period: 24h

      storage:
        type: s3
        s3:
          s3forcepathstyle: true
          insecure: true

      ingester:
        chunk_encoding: snappy

      structuredConfig:
        auth_enabled: false
        ingester:
          chunk_encoding: snappy

        common:
          storage:
            s3:
              s3forcepathstyle: true
        server:
          log_level: info
          http_listen_port: 3100
          grpc_listen_port: 9095

          grpc_server_max_recv_msg_size: 8388608
          grpc_server_max_send_msg_size: 8388608

        limits_config:
          ingestion_burst_size_mb: 128
          ingestion_rate_mb: 64
          max_query_parallelism: 100
          per_stream_rate_limit: 64M
          per_stream_rate_limit_burst: 128M
          reject_old_samples: true
          reject_old_samples_max_age: 168h
          retention_period: 30d
          shard_streams:
            enabled: true
          split_queries_by_interval: 1h
        # If this is configured at all, it gets mistemplated and tries using bucketname.bucketendpoint instead of bucketendpoint/bucketname
        # compactor:
        #   working_directory: /var/loki/compactor/retention
        #   delete_request_store: s3
        #   retention_enabled: true

        query_scheduler:
          max_outstanding_requests_per_tenant: 4096

        frontend:
          max_outstanding_per_tenant: 4096

        ruler:
          storage:
            type: local
            local:
              directory: /rules
          rule_path: /tmp/scratch
          enable_alertmanager_v2: true
          alertmanager_url: http://prometheus-alertmanager.monitoring.svc:9093
          enable_api: true

        analytics:
          reporting_enabled: false
    test:
      enabled: false

    monitoring:
      dashboards:
        enabled: true
        annotations:
          grafana_folder: loki
        labels:
          grafana_dashboard: "1"
      serviceMonitor:
        enabled: true
        metricsInstance:
          enabled: false
      selfMonitoring:
        enabled: false
        grafanaAgent:
          installOperator: false
      rules:
        enabled: true
        alerting: true
      alerts:
        enabled: true

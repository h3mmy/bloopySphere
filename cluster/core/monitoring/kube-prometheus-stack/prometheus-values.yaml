prometheus:
  enabled: true
  service:
    ipFamilyPolicy: PreferDualStack
    ipFamilies:
      - "IPv4"
      - "IPv6"
  ingress:
    enabled: true
    pathType: Prefix
    ingressClassName: "traefik"
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-production
      traefik.ingress.kubernetes.io/router.entrypoints: websecure
      hajimari.io/instance: "bloop-quarky"
      hajimari.io/enable: "true"
      hajimari.io/appName: "Prometheus"
    hosts:
      - &promhost "prometheus.${XYZ_DOMAIN}"
    tls:
      - hosts:
          - *promhost
        secretName: tls.prometheus

  thanosIngress:
    enabled: true
    pathType: Prefix
    ingressClassName: traefik
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt-production
      traefik.ingress.kubernetes.io/service.serversscheme: h2c
    hosts:
      - &host "thanos-sidecar.${XYZ_DOMAIN}"
    tls:
      - hosts:
          - *host
        secretName: tls.thanos-sidecar
  thanosService:
    enabled: true
  thanosServiceMonitor:
    enabled: true

  prometheusSpec:
    resources:
      requests:
        memory: 3250Mi
        cpu: 250m
      limits:
        memory: 8200Mi
    enableAdminAPI: true
    podAntiAffinity: hard
    podMonitorNamespaceSelector: {}
    podMonitorSelector: {}
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false
    replicaExternalLabelName: "replica"
    replicas: 2
    retention: 6h
    retentionSize: 8GB
    ruleSelector: {}
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorNamespaceSelector: {}
    serviceMonitorSelector: {}
    serviceMonitorSelectorNilUsesHelmValues: false
    walCompression: true

    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: "ceph-block"
          resources:
            requests:
              storage: 15Gi
    thanos:
      image: quay.io/thanos/thanos:v0.26.0
      # renovate: datasource=docker depName=quay.io/thanos/thanos
      version: v0.26.0
      objectStorageConfig:
        name: thanos-objstore-secret
        key: objstore.yml

    addtionalScrapeConfigs:
      - job_name: minio-job
        honor_timestamps: true
        metrics_path: /minio/v2/metrics/cluster
        static_configs:
          - targets:
              - "minio.storage.svc.cluster.local:9000"
      - job_name: "blocky"
        honor_timestamps: true
        static_configs:
          - targets:
              - "blocky.networking.svc.cluster.local:4000"
      - job_name: "uptimerobot"
        params:
          script: [uptimerobot]
        static_configs:
          - targets:
              - "uptimerobot-prometheus.monitoring.svc.cluster.local:9705"
        scrape_interval: 5m
        scrape_timeout: 90s
      - job_name: "coredns"
        honor_timestamps: true
        static_configs:
          - targets:
              - "coredns-metrics.kube-system:9153"
      - job_name: "jupyterhub"
        scrape_interval: 5m
        scrape_timeout: 90s
        honor_timestamps: true
        metrics_path: /metrics
        static_configs:
          - targets:
              - "proxy-api.svc.cluster.local:8001"
      - job_name: "home-assistant"
        scrape_interval: 60s
        metrics_path: /api/prometheus
        honor_timestamps: true
        # Long-Lived Access Token
        authorization:
          credentials: "${HASS_PROM_TOKEN}"
        scheme: http
        static_configs:
          - targets:
              - home-assistant.home.svc.cluster.local:8123
            labels:
              app.kubernetes.io/name: home-assistant

      - job_name: "linkerd-controller"
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - linkerd
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_pod_container_port_name
            action: keep
            regex: admin-http
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: replace
            target_label: component

      - job_name: "linkerd-service-mirror"
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_pod_label_linkerd_io_control_plane_component
              - __meta_kubernetes_pod_container_port_name
            action: keep
            regex: linkerd-service-mirror;admin-http$
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: replace
            target_label: component

      - job_name: "linkerd-proxy"
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_pod_container_name
              - __meta_kubernetes_pod_container_port_name
              - __meta_kubernetes_pod_label_linkerd_io_control_plane_ns
            action: keep
            regex: ^{{default .Values.proxyContainerName "linkerd-proxy" .Values.proxyContainerName}};linkerd-admin;{{.Values.linkerdNamespace}}$
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod
          # special case k8s' "job" label, to not interfere with prometheus' "job"
          # label
          # __meta_kubernetes_pod_label_linkerd_io_proxy_job=foo =>
          # k8s_job=foo
          - source_labels: [__meta_kubernetes_pod_label_linkerd_io_proxy_job]
            action: replace
            target_label: k8s_job
          # drop __meta_kubernetes_pod_label_linkerd_io_proxy_job
          - action: labeldrop
            regex: __meta_kubernetes_pod_label_linkerd_io_proxy_job
          # __meta_kubernetes_pod_label_linkerd_io_proxy_deployment=foo =>
          # deployment=foo
          - action: labelmap
            regex: __meta_kubernetes_pod_label_linkerd_io_proxy_(.+)
          # drop all labels that we just made copies of in the previous labelmap
          - action: labeldrop
            regex: __meta_kubernetes_pod_label_linkerd_io_proxy_(.+)
          # __meta_kubernetes_pod_label_linkerd_io_foo=bar =>
          # foo=bar
          - action: labelmap
            regex: __meta_kubernetes_pod_label_linkerd_io_(.+)
          # Copy all pod labels to tmp labels
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
            replacement: __tmp_pod_label_$1
          # Take `linkerd_io_` prefixed labels and copy them without the prefix
          - action: labelmap
            regex: __tmp_pod_label_linkerd_io_(.+)
            replacement: __tmp_pod_label_$1
          # Drop the `linkerd_io_` originals
          - action: labeldrop
            regex: __tmp_pod_label_linkerd_io_(.+)
          # Copy tmp labels into real labels
          - action: labelmap
            regex: __tmp_pod_label_(.+)
